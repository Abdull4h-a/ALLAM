{"cells":[{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[],"source":["from IPython.display import clear_output"]},{"cell_type":"code","execution_count":1,"metadata":{"executionInfo":{"elapsed":743,"status":"ok","timestamp":1728681287797,"user":{"displayName":"Telha Bin Bilal","userId":"04147761314111353462"},"user_tz":-300},"id":"FYr_Ntv3t3yY"},"outputs":[{"name":"stderr","output_type":"stream","text":["c:\\Users\\Telha Bilal\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n","  from .autonotebook import tqdm as notebook_tqdm\n"]}],"source":["import random\n","import json\n","\n","import torch\n","import torch.nn as nn\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","from tqdm import tqdm\n","\n","from transformers import AutoModel\n","\n","import numpy as np"]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1728681287797,"user":{"displayName":"Telha Bin Bilal","userId":"04147761314111353462"},"user_tz":-300},"id":"38oZ5y6fp_Jz"},"outputs":[],"source":["from ibm_watsonx_ai.foundation_models import Model"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[],"source":["test_df = pd.read_csv('train_data.csv')"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[],"source":["author_to_idx_mapping = {name: i for i, name in enumerate(test_df['AuthorName'].sort_values().unique().tolist())}\n","idx_to_author_mapping = {v: k for k, v in author_to_idx_mapping.items()}"]},{"cell_type":"markdown","metadata":{},"source":["## Initializing the model"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[],"source":["class TextClassifier(nn.Module):\n","    def __init__(self, input_size=1024, hidden_size=512, num_classes=10):\n","        super(TextClassifier, self).__init__()\n","        self.fc1 = nn.Linear(input_size, hidden_size)\n","        self.ln1 = nn.LayerNorm(hidden_size)  # LayerNorm after the first layer\n","        self.relu = nn.ReLU()\n","        self.fc2 = nn.Linear(hidden_size, hidden_size // 2)\n","        self.ln2 = nn.LayerNorm(hidden_size // 2)  # LayerNorm after the second layer\n","        self.fc3 = nn.Linear(hidden_size // 2, num_classes)\n","\n","    def forward(self, x):\n","        x = self.fc1(x)\n","        x = self.ln1(x)  # Apply layer normalization\n","        x = self.relu(x)\n","        x = self.fc2(x)\n","        x = self.ln2(x)  # Apply layer normalization\n","        x = self.relu(x)\n","        x = self.fc3(x)\n","        x = torch.softmax(x, dim=-1)\n","        return x"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[],"source":["device = 'cuda' if torch.cuda.is_available() else 'cpu'"]},{"cell_type":"code","execution_count":12,"metadata":{},"outputs":[],"source":["embedding_model = AutoModel.from_pretrained(\"jinaai/jina-embeddings-v3\", trust_remote_code=True).to(device)\n","\n","clear_output()"]},{"cell_type":"code","execution_count":13,"metadata":{},"outputs":[{"data":{"text/plain":["TextClassifier(\n","  (fc1): Linear(in_features=1024, out_features=1024, bias=True)\n","  (ln1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","  (relu): ReLU()\n","  (fc2): Linear(in_features=1024, out_features=512, bias=True)\n","  (ln2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","  (fc3): Linear(in_features=512, out_features=10, bias=True)\n",")"]},"execution_count":13,"metadata":{},"output_type":"execute_result"}],"source":["input_dim = 1024\n","hidden_dim = 1024\n","n_classes = len(author_to_idx_mapping)\n","\n","classification_head = TextClassifier(input_dim, hidden_dim, n_classes)\n","classification_head.load_state_dict(torch.load('author_classifier_head_jina_embeddings.pt'))\n","classification_head.to(device)"]},{"cell_type":"code","execution_count":69,"metadata":{},"outputs":[],"source":["def get_classification_logits(inputs):\n","    \n","    with torch.no_grad():\n","\n","        embeddings = embedding_model.encode(inputs, max_length=2048)\n","        embeddings = torch.from_numpy(embeddings).to(device)\n","        class_logits = classification_head(embeddings)\n","    \n","    return class_logits\n","\n","\n","def classify(inputs):\n","\n","    \n","    logits = get_classification_logits(inputs)\n","    classes = torch.argmax(logits, -1)\n","    \n","    return classes.tolist()\n","\n","\n","def classify_and_get_prob(inputs, author_names):\n","\n","    if isinstance(author_names, str):\n","        author_names = [author_names]*len(inputs)\n","\n","    logits = get_classification_logits(inputs).tolist()\n","\n","    probs = [logit[author_to_idx_mapping[author_name]] for logit, author_name in zip(logits, author_names)]\n","    return probs\n"]},{"cell_type":"code","execution_count":15,"metadata":{},"outputs":[],"source":["tdf = test_df.sample(n=2).copy()\n","tauthors = tdf['AuthorName'].tolist()\n","classes = classify(tdf['ChapterText'].tolist())"]},{"cell_type":"code","execution_count":16,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["['أبو حيان التوحيدي', 'ثورنتون دبليو برجس'] ['أبو حيان التوحيدي', 'ثورنتون دبليو برجس']\n"]}],"source":["touts = [idx_to_author_mapping[i] for i in classes]\n","\n","print(tauthors, touts)"]},{"cell_type":"markdown","metadata":{},"source":["## Preparing ALLAM API model"]},{"cell_type":"code","execution_count":17,"metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1728678561982,"user":{"displayName":"Telha Bin Bilal","userId":"04147761314111353462"},"user_tz":-300},"id":"nD-Yl-71_SFS"},"outputs":[],"source":["credentials = {\"url\": \"https://eu-de.ml.cloud.ibm.com\", \"apikey\": \"JsA-9hFRsH1msnDzUkcRpoUhSi3r3dfQMAj8Ic9yRiNg\"}\n","\n","project_id = \"43ada3b1-5d11-42e8-9ef1-c718b99c05e1\"\n","model_id = \"sdaia/allam-1-13b-instruct\"\n","\n","parameters = {\n","    # \"decoding_method\": \"greedy\",\n","    \"max_new_tokens\": 500,\n","    # \"repetition_penalty\": 1.05\n","}"]},{"cell_type":"code","execution_count":18,"metadata":{"executionInfo":{"elapsed":2425,"status":"ok","timestamp":1728678564404,"user":{"displayName":"Telha Bin Bilal","userId":"04147761314111353462"},"user_tz":-300},"id":"j4-ph1C6rLAy"},"outputs":[],"source":["# Initialize the model\n","model = Model(\n","    model_id=model_id,\n","    params=parameters,\n","    credentials=credentials,\n","    project_id=project_id\n",")"]},{"cell_type":"markdown","metadata":{"id":"JjxStB1NAOK-"},"source":["## Testing the performance"]},{"cell_type":"code","execution_count":19,"metadata":{},"outputs":[],"source":["def preprocess_text(text):\n","\n","    words = text.split()\n","    words = words[:400]\n","    processed_text = ' '.join(words)\n","\n","    return processed_text"]},{"cell_type":"code","execution_count":20,"metadata":{},"outputs":[],"source":["PROMPT_TEMPLATE = \"\"\"\n","You are an expert text analyst specializing in authorship identification.\n","You will first be given several text pieces, all written by the same known author, to analyze their unique writing style, including linguistic patterns, tone, sentence structure, word choice, and overall style.\n","Afterward, you will be presented with an unknown article.\n","Your task is to critically analyze the writing style of the known text pieces and rewrite the unknown article in the same style.\n","Make sure that the content of the actual article does not change. Only it's writing style.\n","\n","AUTHOR NAME:\n","{author_name}\n","\n","KNOWN TEXT PIECES:\n","{known_articles}\n","\n","UNKNOWN TEXT PIECES:\n","{unknown_article}\n","\n","REWRITTEN TEXT:\n","\"\"\""]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# 10 authors x 3 experiments/author = 30 total experiments\n","\n","# for every experiment, the known text comes from author's own texts\n","# the unknown text comes from a random author which is not our target author."]},{"cell_type":"code","execution_count":35,"metadata":{"id":"T8q-9yJnjG5-"},"outputs":[{"name":"stderr","output_type":"stream","text":["100%|██████████| 10/10 [03:40<00:00, 22.09s/it]\n"]}],"source":["n_exp_per_author = 3\n","# author_to_rewrites = {}\n","rewrites_data = []\n","\n","for author in tqdm(author_to_idx_mapping.keys()):\n","\n","    author_mask = test_df['AuthorName']==author\n","    author_df = test_df[author_mask]\n","    non_author_df = test_df[~author_mask]\n","\n","    prompts = []\n","    input_samples = []\n","\n","    for _ in range(n_exp_per_author):\n","\n","        author_examples = author_df.sample(n=2)['ChapterText'].apply(preprocess_text).tolist()\n","\n","        input_row = non_author_df.sample(n=1).iloc[0]\n","        input_author_name = input_row['AuthorName']\n","        input_text = preprocess_text(input_row['ChapterText'])\n","\n","        prompt = PROMPT_TEMPLATE.format(author_name=author,\n","                                        known_articles='\\n'.join([f'{i}.   {exp}' for i, exp in enumerate(author_examples, 1)]),\n","                                        unknown_article=input_text)\n","        \n","        input_samples.append([author, author_examples, input_author_name, input_text])\n","        prompts.append(prompt)\n","        \n","    allam_rewritten_texts = model.generate_text(prompts, concurrency_limit=len(prompts))\n","\n","    for sample, allam_rewritten_text in zip(input_samples, allam_rewritten_texts):\n","        sample.append(allam_rewritten_text)\n","        rewrites_data.append(sample)"]},{"cell_type":"code","execution_count":36,"metadata":{},"outputs":[{"data":{"text/plain":["30"]},"execution_count":36,"metadata":{},"output_type":"execute_result"}],"source":["len(rewrites_data)"]},{"cell_type":"code","execution_count":37,"metadata":{},"outputs":[],"source":["tgt_author_names, tgt_author_examples, input_author_names, inputs, allam_outputs = list(zip(*rewrites_data))"]},{"cell_type":"code","execution_count":54,"metadata":{},"outputs":[],"source":["rewritten_df = pd.DataFrame({\n","    'target_author_name': tgt_author_names,\n","    'target_author_examples': tgt_author_examples,\n","    'input_author_name': input_author_names,\n","    'input': inputs,\n","    'rewrite': allam_outputs\n","})"]},{"cell_type":"code","execution_count":55,"metadata":{},"outputs":[],"source":["predicted_classes = classify(rewritten_df['rewrite'].tolist())"]},{"cell_type":"code","execution_count":56,"metadata":{},"outputs":[{"data":{"text/plain":["30"]},"execution_count":56,"metadata":{},"output_type":"execute_result"}],"source":["len(predicted_classes)"]},{"cell_type":"code","execution_count":61,"metadata":{},"outputs":[],"source":["predicted_authors = [idx_to_author_mapping[idx] for idx in predicted_classes]\n","rewritten_df['predicted_author_name'] = predicted_authors"]},{"cell_type":"code","execution_count":71,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>target_author_name</th>\n","      <th>target_author_examples</th>\n","      <th>input_author_name</th>\n","      <th>input</th>\n","      <th>rewrite</th>\n","      <th>predicted_author_name</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>2</th>\n","      <td>أبو حيان التوحيدي</td>\n","      <td>[قال لي ليلة أخرى: ألا تتمِّم ما كنا به بدأْنا...</td>\n","      <td>سليم حسن</td>\n","      <td>إن أقدم عهد إقطاعي معلوم لنا من النقوش المصرية...</td>\n","      <td>\\nفي زمان هؤلاءِ من يُلْحَق بهم، ويَدخُل في زم...</td>\n","      <td>محمد لطفي جمعة</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>زكي نجيب محمود</td>\n","      <td>[في أوائل عام ١٩٥٦م تلقيت عرضًا من دار كبرى لل...</td>\n","      <td>أبو حيان التوحيدي</td>\n","      <td>هذه المسألة مكررة وقد مضى الجواب عنها مستقصًى ...</td>\n","      <td>\\nفي أوائل عام ١٩٥٦م، تلقيت عرضًا من دار نشر أ...</td>\n","      <td>زكي نجيب محمود</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>ثورنتون دبليو برجس</td>\n","      <td>[لَمْ يَكُنْ طَائِرُ الْقَرْقَفِ تومي وَنَقَّا...</td>\n","      <td>زكي نجيب محمود</td>\n","      <td>تسعة قُرَّاء من كل عشرة، لم يسمعوا من الفلسفة ...</td>\n","      <td>\\nفي هذا المقال، سنستكشف أسلوب الكتابة الفريد ...</td>\n","      <td>سليم حسن</td>\n","    </tr>\n","    <tr>\n","      <th>22</th>\n","      <td>نقولا حداد</td>\n","      <td>[في ربيع سنة ١٨٩٠ كان الإمبراطور فرنسوا جوزف م...</td>\n","      <td>ثورنتون دبليو برجس</td>\n","      <td>عِنْدَمَا صَادَفَ أَنْ سَمِعَ سامي الْقُنْدُسَ...</td>\n","      <td>\\nفي ربيع سنة ١٨٩٠، كان الإمبراطور فرنسوا جوزف...</td>\n","      <td>نقولا حداد</td>\n","    </tr>\n","    <tr>\n","      <th>28</th>\n","      <td>يوسف إدريس</td>\n","      <td>[(يُفتح الستار على عوض وسعد زغلول يَلعبان على ...</td>\n","      <td>نقولا حداد</td>\n","      <td>التمدن كما نعرفه الآن وكما عرفنا تاريخه الماضي...</td>\n","      <td>\\nفي هذا العمل المسرحي، الجمهور ليس مجرد متفرج...</td>\n","      <td>يوسف إدريس</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["    target_author_name                             target_author_examples  \\\n","2    أبو حيان التوحيدي  [قال لي ليلة أخرى: ألا تتمِّم ما كنا به بدأْنا...   \n","8       زكي نجيب محمود  [في أوائل عام ١٩٥٦م تلقيت عرضًا من دار كبرى لل...   \n","3   ثورنتون دبليو برجس  [لَمْ يَكُنْ طَائِرُ الْقَرْقَفِ تومي وَنَقَّا...   \n","22          نقولا حداد  [في ربيع سنة ١٨٩٠ كان الإمبراطور فرنسوا جوزف م...   \n","28          يوسف إدريس  [(يُفتح الستار على عوض وسعد زغلول يَلعبان على ...   \n","\n","     input_author_name                                              input  \\\n","2             سليم حسن  إن أقدم عهد إقطاعي معلوم لنا من النقوش المصرية...   \n","8    أبو حيان التوحيدي  هذه المسألة مكررة وقد مضى الجواب عنها مستقصًى ...   \n","3       زكي نجيب محمود  تسعة قُرَّاء من كل عشرة، لم يسمعوا من الفلسفة ...   \n","22  ثورنتون دبليو برجس  عِنْدَمَا صَادَفَ أَنْ سَمِعَ سامي الْقُنْدُسَ...   \n","28          نقولا حداد  التمدن كما نعرفه الآن وكما عرفنا تاريخه الماضي...   \n","\n","                                              rewrite predicted_author_name  \n","2   \\nفي زمان هؤلاءِ من يُلْحَق بهم، ويَدخُل في زم...        محمد لطفي جمعة  \n","8   \\nفي أوائل عام ١٩٥٦م، تلقيت عرضًا من دار نشر أ...        زكي نجيب محمود  \n","3   \\nفي هذا المقال، سنستكشف أسلوب الكتابة الفريد ...              سليم حسن  \n","22  \\nفي ربيع سنة ١٨٩٠، كان الإمبراطور فرنسوا جوزف...            نقولا حداد  \n","28  \\nفي هذا العمل المسرحي، الجمهور ليس مجرد متفرج...            يوسف إدريس  "]},"execution_count":71,"metadata":{},"output_type":"execute_result"}],"source":["rewritten_df.sample(n=5)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["tgt_eq_pred_mask = rewritten_df['target_author_name']==rewritten_df['predicted_author_name']\n","print('EXACTLY TARGET AUTHOR', len(rewritten_df[tgt_eq_pred_mask]))       # 13\n","print('NOT EXACTLY TARGET AUTHOR', len(rewritten_df[~tgt_eq_pred_mask]))  # 17"]},{"cell_type":"code","execution_count":73,"metadata":{},"outputs":[],"source":["unmodified_input_tgt_author_probs = classify_and_get_prob(rewritten_df['input'].tolist(), rewritten_df['target_author_name'].tolist())\n","rewritten_input_tgt_author_probs = classify_and_get_prob(rewritten_df['rewrite'].tolist(), rewritten_df['target_author_name'].tolist())"]},{"cell_type":"code","execution_count":80,"metadata":{},"outputs":[],"source":["unmodified_input_tgt_author_probs = pd.Series(unmodified_input_tgt_author_probs)\n","rewritten_input_tgt_author_probs = pd.Series(rewritten_input_tgt_author_probs)"]},{"cell_type":"code","execution_count":85,"metadata":{},"outputs":[{"data":{"text/plain":["29"]},"execution_count":85,"metadata":{},"output_type":"execute_result"}],"source":["(rewritten_input_tgt_author_probs > unmodified_input_tgt_author_probs).sum()"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[{"data":{"text/plain":["0.9666666666666667"]},"execution_count":3,"metadata":{},"output_type":"execute_result"}],"source":["29/30"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# make some generations using allam\n","# calculate the probability of target author\n","# loss = (1-probability)\n","\n","# generations = model(input)\n","# \n"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyNGRBNVyx+7/6WLaHPVbytB","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.2"}},"nbformat":4,"nbformat_minor":0}
